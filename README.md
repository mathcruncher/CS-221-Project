# CS-221-Project
An incredible amount of communication is transmitted across social media and Internet forums: Facebook Messenger and WhatsApp alone handle over 60 billion messages per day. Identifying and eliminating abuse on the Internet remains a long-term goal to ensure all feel safe and supported in society. Using a dataset of text annotated with emotional scores perceived by the writer as well as readers, models were trained for fine-tuned sentiment analysis. Three regression models predicting emotional scores for text were compared: a multi-linear regression model, an MLP (Multi-layered perceptron) network, and an LSTM (Long Short-Term Memory Network). We evaluate emotional predictions for a general dataset, then do additional training on a small hand-crafted cyberbully and harassment dataset. Based on the predicted emotional scores, we classify harmful text using static score thresholds. Our results show that neural networks, especially LSTMs, can achieve optimal performance in accurately scoring text across emotional dimensions, which can then be used to effectively identify cyberbullying threats across social media and online communications platforms.
