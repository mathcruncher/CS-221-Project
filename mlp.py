# -*- coding: utf-8 -*-
"""MLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/151OON10upD4IY9Vhyk7nRFtshSznGBA-
"""

# Imports
from collections import Counter 
from pandas import read_csv
import nltk
import keras
from keras.models import Sequential
from keras.layers import Dense
from keras.wrappers.scikit_learn import KerasRegressor
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
from scipy.stats import pearsonr
from scipy.stats import spearmanr
from keras.layers import Input, Dense
from keras.models import Model
import numpy as np
from sklearn.model_selection import train_test_split
from keras.preprocessing.text import Tokenizer

import matplotlib.pyplot as plt
from sklearn import svm, datasets
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from sklearn.utils.multiclass import unique_labels

def process_text(s):
  '''
  The dataset is comprised of only English reviews.
  All text has been converted to lowercase.
  There is white space around punctuation like periods, commas, and brackets.
  Text has been split into one sentence per line.
  '''
  s = s.lower()

  punctuation_set = {'.', '?', '!', ',', '?', '@', '\"', '\'', '\\', '/', '#', '$', '%', '^', '~', '&', '*', '(', ')', '[', ']', '{', '}', '|'}
  n = len(s)
  next_char = None
  # iterate backwards through string, adding space to the left if current char is not punctuation and next char is
  for i in range(n - 2, -1, -1):
    if s[i] not in punctuation_set and s[i + 1] in punctuation_set:
        s = s[:i + 1] + ' ' + s[i+1:]

  # iterate backwards through string, adding space to the right if current char is not punctuation and next char is
  for i in range(n - 2, -1, -1):
    if s[i] in punctuation_set and s[i + 1] not in punctuation_set:
        s = s[:i + 1] + ' ' + s[i+1:]

  return ' '.join(s.split())

s = process_text('In their December, 1995 review of the nation\'s best charities, U.S. News & World Report called Goodwill one of the five \"Standout Good Guys.\"')
print(s)

nltk.download('stopwords')
from nltk.corpus import stopwords
import string
def get_tokens(doc):
	tokens = doc.split()
	table = str.maketrans('', '', string.punctuation)
	tokens = [w.translate(table) for w in tokens]
	tokens = [word for word in tokens if word.isalpha()]
	stop_words = set(stopwords.words('english'))
	tokens = [w for w in tokens if not w in stop_words]
	tokens = [word for word in tokens if len(word) > 1]
	return tokens
print(get_tokens(s))

vocab = Counter()
dataframe = read_csv("emobank.csv", header=[0])
print(dataframe)

# get vocab from train
for s in dataframe["text"]:
  tokens = get_tokens(process_text(s))
  vocab.update(tokens)

# process test
sent_list = []
min_occurance = 2
for s in dataframe["text"]:
  tokens = get_tokens(process_text(s))
  tokens = [w for w in tokens if w in vocab] #and vocab[w] >= min_occurance]
  sent_list.append(' '.join(tokens))

print(vocab)
print(len(vocab))
print()
print(len(sent_list))

# keep tokens with a min occurrence


print(set(vocab.keys()))

tokenizer = Tokenizer()
# fit the tokenizer on the documents
tokenizer.fit_on_texts(sent_list)
x = tokenizer.texts_to_matrix(sent_list, mode='freq')
y = dataframe["V"]
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)

#train_set = sent_list[:8050]
#test_set = sent_list[8050:]



''' 
# encode training data set
x_train = tokenizer.texts_to_matrix(train_set, mode='freq')
'''
print(x_train.shape)
print(x_train)
print()

'''
x_test = tokenizer.texts_to_matrix(test_set, mode='freq')
'''
print(x_test.shape)
print(x_test)

n_words = x_train.shape[1]
'''y_train = []
y_test = []

count = 1
for val in dataframe["V"]:
  if count <= 8050:
    y_train.append(val)
  else:
    y_test.append(val)
  count += 1
'''
print(list(y_train))
print(list(y_test))

print(n_words)
#first_layers = ['elu', 'softmax', 'selu', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'exponential', 'linear']
losses = ['mean_squared_error']
optimizers = ['SGD', 'RMSprop', ]
neurons = [4]

class TestCallback(keras.callbacks.Callback):
    def __init__(self, test_data):
        self.test_data = test_data

    def on_epoch_end(self, epoch, logs={}):
        a, b = self.test_data
        print(self.model.evaluate(a, b, verbose=0))
        #loss, acc = self.model.evaluate(a, b, verbose=0)
        #print('\nTesting loss: {}, acc: {}\n'.format(loss, acc))


for neuron in neurons:
  print(neuron, "neurons")
  model = Sequential()
  model.add(Dense(4, input_shape=(n_words,), kernel_initializer='normal', activation='softplus'))
  model.add(Dense(2, kernel_initializer='normal', activation='softplus'))
  model.add(Dense(2, kernel_initializer='normal', activation='softplus'))
  model.add(Dense(1, kernel_initializer='normal')) 
  # compile network


  model.compile(loss='mean_squared_error', optimizer='adam')
  # fit network
  model.fit(x_train, y_train, epochs=20, verbose=1) #, callbacks=[TestCallback((x_test, y_test))])
  # evaluate

  import numpy as np
  prediction = model.predict(x_test).flatten()
  assert len(prediction) == len(y_test)
  n = len(prediction)

  correct = 0
  wrong = 0

  error = 0

  y_train = list(y_train)
  y_test = list(y_test)
  for i in range(n):
    if abs(prediction[i] - y_test[i]) <= 0.3:
      correct += 1
    else:
      wrong += 1
    
    error += abs(prediction[i] - y_test[i])
    #print(prediction[i], y_test[i], abs(prediction[i] - y_test[i]))

  #print(correct)
  #print(wrong)
  print("Accuracy: ", 100 * correct/(correct + wrong), '%', "Average error",error / (correct + wrong))
  
  #loss, acc = model.evaluate(x_test, y_test, verbose=2)
  #print('Test Accuracy: %f' % (acc*100))

corr, _ = pearsonr(prediction, y_test)
print(corr)
corr, _ = spearmanr(prediction, y_test)
print('Spearmans correlation: %.3f' % corr)

prediction = model.predict(x_test).flatten()
assert len(prediction) == len(y_test)
n = len(prediction)
print(prediction)
print(y_test)

correct = 0
wrong = 0

error = 0

y_train = list(y_train)
y_test = list(y_test)

for i in range(n):
  if abs(prediction[i] - y_test[i]) <= 0.3:
    correct += 1
  else:
    wrong += 1
  
  error += abs(prediction[i] - y_test[i])
  if abs(prediction[i] - y_test[i]) > 1:
    print(x_test[i], prediction[i], y_test[i], abs(prediction[i] - y_test[i]))

print(correct)
print(wrong)
print("Accuracy: ", 100 * correct/(correct + wrong), '%')
print(error / (correct + wrong))
#loss, acc = model.evaluate(x_test, y_test, verbose=2)
#print('Test Accuracy: %f' % (acc*100))

print(dataframe['D'].median())
print(dataframe['A'].median())
print(dataframe['V'].median())

n = len(dataframe['D'])
print(n)
count = 0
for i in range(8049, n):
  if dataframe['D'][i] >= 3.2 and dataframe['V'][i] <= 2.5:
    #print(dataframe['text'][i])
    #print()
    count += 1

print(count)
print(count / n)

x = tokenizer.texts_to_matrix(sent_list, mode='freq')
def train_model(x_train_param, y_train_param, k):
  inputs = Input(shape=(784,))
  
  
  inputs = Input(shape=(n_words,))
  output_1 = Dense(k, activation='softplus', kernel_initializer='normal')(inputs)
  #output_2 = Dense(2, kernel_initializer='normal', activation='softplus')(output_1)
  #output_3 = Dense(2, kernel_initializer='normal', activation='softplus')(output_2)
  val_pred = Dense(1, kernel_initializer='normal')(output_1)
  aro_pred = Dense(1, kernel_initializer='normal')(output_1)
  dom_pred = Dense(1, kernel_initializer='normal')(output_1)

  model = Model(inputs=inputs, outputs=[val_pred, aro_pred, dom_pred])

  '''
  model = Sequential()
  model.add(Dense(4, input_shape=(n_words,), kernel_initializer='normal', activation='softplus'))
  model.add(Dense(2, kernel_initializer='normal', activation='softplus'))
  model.add(Dense(2, kernel_initializer='normal', activation='softplus'))
  model.add(Dense(1, kernel_initializer='normal'))
  '''
  model.compile(loss='mean_squared_error', optimizer='adam')
  model.fit(x_train_param, y_train_param, epochs=40, verbose=0)
  return model

def get_results(my_model):
  prediction = list(my_model.predict(x[8049:])[2].flatten())
  actual_results = list(dataframe["D"][8049:])
  print(prediction)
  assert len(prediction) == len(actual_results)
  n = len(prediction)

  correct = 0
  wrong = 0

  error = 0

  for i in range(n):
    if abs(prediction[i] - actual_results[i]) <= 0.3:
      correct += 1
    else:
      wrong += 1
    
    error += abs(prediction[i] - actual_results[i])
    #print(prediction[i], y_test[i], abs(prediction[i] - y_test[i]))

  #print(correct)
  #print(wrong)
  print("Accuracy: ", 100 * correct/(correct + wrong), '%', "Average error",error / (correct + wrong))

for k in [1,2,3,4,5,10,20]:
  my_model = train_model(x[:8049], [dataframe["V"][:8049], dataframe["A"][:8049], dataframe["D"][:8049]], k)
  get_results(my_model)

valence_model = train_model(x[:8049], dataframe["V"][:8049])
#arousal_model = train_model(x[:8049], dataframe["A"][:8049])
#dominance_model = train_model(x[:8049], dataframe["D"][:8049])





def find_bullying(my_model, x_test_param):
  print(my_model.predict(x_test_param))
  valence_prediction = my_model.predict(x_test_param)[0].flatten()
  dominance_prediction = my_model.predict(x_test_param)[2].flatten()
  length = len(valence_prediction)
  print(length)
  count = 0
  true_pos = 0
  false_pos = 0
  true_neg = 0
  false_neg = 0

  for i in range(length):
    actual = dataframe["V"][i + 8049] <= 2.5 and dataframe["D"][i + 8049] >= 3.2
    model_detected = valence_prediction[i] <= 2.5 and dominance_prediction[i] >= 3.2

    if not actual and not model_detected:
      true_neg += 1
      continue 

    if actual and model_detected:
      print("true positive")
      true_pos += 1
    elif model_detected:
      print("false positive")
      false_pos += 1
      print(dataframe['text'][i + 8049])
    else:
      print("false negative")
      false_neg += 1

    print("predicted: ", valence_prediction[i], dominance_prediction[i], "actual: ", dataframe["V"][i + 8049], dataframe["D"][i + 8049])
    
    print()
    count += 1

  print(count)
  print(count / n)
  print(true_pos, true_neg, false_pos, false_neg)

#find_bullying(valence_model, dominance_model, x[8049:])
find_bullying(my_model, x[8049:])

valence_model = train_model(x, dataframe["V"])
arousal_model = train_model(x, dataframe["A"])
dominance_model = train_model(x, dataframe["D"])

valence_prediction = valence_model.predict(x).flatten()
arousal_prediction = arousal_model.predict(x).flatten()
dominance_prediction = dominance_model.predict(x).flatten()

import numpy as np
bully_model = Sequential()
bully_model.add(Dense(4, input_shape=(n_words + 3,), kernel_initializer='normal', activation='relu'))
bully_model.add(Dense(10, kernel_initializer='normal', activation='relu'))
bully_model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))
bully_model.compile(loss='binary_crossentropy', optimizer='adam')

'''
import keras.backend as K
import tensorflow as tf
def compute_binary_specificity(y_pred, y_true):
  true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))	
  predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))	
  p = true_positives / (predicted_positives + K.epsilon())
  possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))	
  r = true_positives / (possible_positives + K.epsilon())	
  return (2 * p * r) / (p + r + K.epsilon())

def specificity_loss_wrapper():
    def specificity_loss(y_true, y_pred):
        return compute_binary_specificity(y_true, y_pred)
    return specificity_loss
spec_loss = specificity_loss_wrapper()
#bully_model.compile(loss=spec_loss, optimizer='adam')
'''

x_copy = x.copy()

valence_col = valence_prediction.reshape((valence_prediction.shape[0],1))
arousal_col = arousal_prediction.reshape((arousal_prediction.shape[0],1))
dominance_col = dominance_prediction.reshape((dominance_prediction.shape[0],1))

bully_x = np.hstack((x_copy, valence_col))
bully_x = np.hstack((bully_x, arousal_col))
bully_x = np.hstack((bully_x, dominance_col))
bully_train_x = bully_x[:8049]
bully_test_x = bully_x[8049:]

bully_train_y = []
bully_test_y = []
for i in range(8049):
  if dataframe["V"][i] <= 2.5 and dataframe["D"][i] >= 3.2:
    bully_train_y.append(1)
  else:
    bully_train_y.append(0)

for i in range(8049, len(dataframe['D'])):
  if dataframe["V"][i] <= 2.5 and dataframe["D"][i] >= 3.2:
    bully_test_y.append(1)
  else:
    bully_test_y.append(0)

bully_model.fit(bully_train_x, bully_train_y, epochs=20, verbose=1)



bully_predict = bully_model.predict(bully_test_x).flatten()
print(sorted(bully_predict))


 
true_pos = 0
false_pos = 0
true_neg = 0
false_neg = 0
for i in range(len(bully_predict)):
  actual = bully_test_y[i]
  model_detected = bully_predict[i] >= 0.03
  if actual and model_detected:
    #print("true positive")
    true_pos += 1
    

  elif model_detected:
    #print("false positive")
    false_pos += 1
    
  elif actual:
    #print("false negative")
    print(dataframe['text'][i + 8049])
    print(valence_prediction[i], dataframe['V'][i + 8049])
    print(arousal_prediction[i], dataframe['A'][i + 8049])
    print(dominance_prediction[i], dataframe['D'][i + 8049])
    false_neg += 1
  else:
    true_neg += 1
    
print(true_pos, true_neg, false_pos, false_neg)


classes = ["V <= 2.5, D >= 3.2", "Other"]
cm = np.array([[true_pos, false_pos],[false_neg, true_neg]])
fig, ax = plt.subplots()
im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
ax.figure.colorbar(im, ax=ax)
# We want to show all ticks...
ax.set(xticks=np.arange(cm.shape[1]),
        yticks=np.arange(cm.shape[0]),
        # ... and label them with the respective list entries
        xticklabels=classes, yticklabels=classes,
        title="Confusion Matrix",
        ylabel='True label',
        xlabel='Predicted label')

# Rotate the tick labels and set their alignment.
plt.setp(ax.get_xticklabels(), rotation=20, ha="right",
          rotation_mode="anchor")

# Loop over data dimensions and create text annotations.
fmt = 'd'
thresh = cm.max() / 2.
for i in range(cm.shape[0]):
    for j in range(cm.shape[1]):
        ax.text(j, i, format(cm[i, j], fmt),
                ha="center", va="center",
                color="white" if cm[i, j] > thresh else "black")
fig.tight_layout()
plt.show()

print(max(dataframe["V"]))
print(max(dataframe["A"]))
print(max(dataframe["D"]))
print(min(dataframe["V"]))
print(min(dataframe["A"]))
print(min(dataframe["D"]))

toxic_df = read_csv("train.csv", header=[0])
text = toxic_df['comment_text'][:10000]
print(text)
t = Tokenizer()
# fit the tokenizer on the documents
t.fit_on_texts(text)
# summarize what was learned
print(t.word_counts)
print(t.document_count)
print(t.word_index)
print(t.word_docs)
#integer encode documents
encoded_docs = t.texts_to_matrix(text, mode='count')
print(encoded_docs)